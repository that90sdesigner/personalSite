---
layout: ../../layouts/MarkdownPostLayout.astro
title: 'Beyond apps: What if operating systems worked like you think?'
date: mar 1, 2024
desc: Latest post
---

## The app-centric model
Operating systems have long followed an app-centric model. Apps on mobile operating systems have been around for 16 years (!) now. People are used to finding an app and opening it to get stuff done.

## Limitations of opening apps
An app-centric OS model has some limitations. Imagine planning a trip - I need one app for flights, another for hotels, and even more for navigating the city and finding things to do. Each app wants me to re-enter the same basic stuff, like my travel dates – over and over again. The whole process feels scattered and slow. 

1. **I don’t want to look for apps first**. When I walk to my desk, I am thinking of picking up things and doing something with it. To write, I might look for a pen and a piece of paper. Or to turn on the light, I look for the switch. Apps have elements that mimic these things (like a virtual switch inside a smart home app) but I still have to look for an app before I do things.
2. **This means switching apps constantly**. For a travel booking, my information is scattered across apps - that booking confirmation in Gmail, the itinerary I wrote in Docs, a place to visit saved in Maps and a recommendation from a friend saved in notes. When looking for information across emails and apps, I have to switch context and different kinds of interfaces. 
3. **Redundancy** - I have to enter the same dates and search for similar details over and over, leaving me feeling inefficient in the process. 


## The future of operating systems 
I see a few trends emerging that might make our operating systems more powerful and less frustrating to use. 

### AI-powered browsing 
2023 bolstered search through AI. While Google evolved search using the Search Generative Experience, new players like Perplexity and ChatGPT’s Turbo emerged in this long-established business of searching the web. 

Today, we browse the web and search using browsers. However, with AI becoming more powerful and conversational, what if there was a browser for the operating system that let you search in files, pull together contacts, scratch notes and more to search information on my phone more efficiently? 

A company called [Rewind AI](https://google.com]) is doing this but I feel it takes this too far by recording every little thing you do on your computer. This is a privacy nightmare. 

Operating systems should be able to find information in apps using natural language and help me get to things and combine information from different apps without having to think of the apps first. I should be able to describe a verb or noun that pulls the right element from the app that is most suitable. Apps then, should exist to give more fine controls to handle information but never become the barrier between the information and the user.


### Multi-modality
While text relates to reading and writing, information is not limited to text. Recent AI models have shown how well information from videos and images can be extracted, understood and used towards creating something new. 

### Interactive modules over apps 
This has been happening for a while now but the majority of users may not have noticed this. Assistive systems like Google Assistant and Siri can manipulate objects in apps directly. Example: Need the weather? I can get a summary without having to open a weather app. Shortcuts on Apple platforms can bring up an interactive date picker within the shortcuts container (again, without opening an app).

Interactive modules are also seen on iOS and Android through a concept called App Slices, that bring up just the right elements to help complete a job. For example, if I want to order at a Panera bread, just the menu and checkout are enough to get your food. 

Another example is using the wallet on my phone to only bring up a credit card and tap to pay. It’d suck to open my bank app and do this every time I have to pay.

